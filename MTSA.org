Multivarite Time Series Analysis

* 概念知识
** 弱平稳
弱平稳就是说Zt的均值和协方差矩阵不依赖于时间t，即zt的前两阶矩不随时间变化。（一个隐函条件是这两个统计变量都是存在的）

k维时间序列的意思是

** 线性
z_t = μ + Σ_(0-)

** 交叉相关矩阵
   + 滞后为l的 *交叉协方差矩阵* ：τ_l=Cov(z_t,z_(t-l)) 
   + 滞后为l的 *交叉相关矩阵* :CCMρ_l = D^-1 τ_1 D^-1

这两个变量的估计方值在1.4有介绍

** 多元混成检验
Ljung-Box检验统计量Q_k(m)

** 自回归模型（AR）、移动平均模型（MA）、自回归移动平均模型（ARMA）以及差分自回归移动平均模型（ARIMA）辨析  
   短期预测是我们做时间序列分析的主要目的。

        时间序列分析的理论基础很简单：设若时间序列（或随机过程）的任一元素yt与其前期元素（yt-1、yt-2等）之间存在着某种关联，则我们可以根据该时间序列的既往观测值来预测其未来的取值。
 
       上述思路的直接体现便是自回归模型。所谓p阶自回归过程（AutoRegressive, AR），简记为AR（p)，指的是如下形式的随机过程：

         yt=a1yt-1+a2yt-2+....+apyt-p+ut

        其中的a1、a2、...、ap是p个待求参数；p是滞后期限的数目；ut为白噪声，也就是满足经典计量经济模型要求的随机误差项。

       一般地说，在经济系统中，任何经济变量的时间序列都可以使用上述自回归过程来描述。但在模型分析的实践中，为简化估计参数的工作量，我们当然希望模型当中的参数尽可能地少。于是便有了引进移动平均过程MA（q）的必要。

       考虑如下形式的（无穷阶）自回归过程：

       yt=ayt-1+a^2yt-2+....+a^pyt-p+....+ut   

将其时间推迟一期，有：

       yt-1=ayt-2+a^2yt-3+....+a^pyt-p-1+ut-1

再将上式两侧的每一项同乘以a，然后与该自回归过程的原始表达式相减，得到：

      yt=ut-aut-1

        我们就把这种由白噪声序列诸元素的加权和所表示的随机过程，称作移动平均过程(moving average process MA)。其中的参数数目就是该移动平均过程的阶数。例如，上式就是一个一阶移动平均过程，简记为MA（1）。

       （本博主2016年11月30日注：在本博文前面所给出的AR（P)模型 yt=a1yt-1+a2yt-2+....+apyt-p+ut中，a1、a2、...、ap中的1、2、...、p均为相应a的下角标；而在这里所给出的无穷阶自回归过程yt=ayt-1+a^2yt-2+....+a^pyt-p+....+ut 中，a^1、a^2、...、a^p中的1、2、...、p均为相应a的上角标，亦即a的一次方、二次方，直至p次方。这就意味着，在前一个AR（P)中，我对自回归系数的取值并无特别要求；但在后一个AR（P)中，我却假设各个自回归系数的取值呈有规律的倍数关系。这纯粹是为了阐述逻辑的需要，是在可接受范围内的逻辑简化。诚如《庖丁解牛》云，臣之所好者，道也，进乎技矣，未尝见全牛也。因此，这种简化分析的能力实在是本博主造诣高超的具体表现，我的造诣显然在“三年之后”矣。呵呵） 

        一般地，q阶移动平均过程MA（q）就是如下形式的随机过程：

       yt=ut-(b1ut-1)-(b2ut-2)-(b3ut-3)-.....-(bqut-q)

       由此可见，移动平均过程实际上是由自回归过程推衍而得的结果。

       我们可以证明：一个平稳有限阶自回归过程必定可以转化成某个无限阶移动平均过程。反之，当某些条件（称之为可转换条件）具备的时候，一个有限阶移动平均过程也可以转换成某个无限阶自回归过程。于是，我们便可以将阶数较高的自回归过程近似地用阶数较低的移动平均过程来代替；反之，亦然。

       那么，对于一个给定的时间序列样本，如何才能以最少的待估参数给出产生这一样本的随机过程呢？

       一般说来，设若时间序列的自相关函数有截断点，即当阶数大于某个数值的时候，其自相关系数开始等于零，但其偏自相关系数却只是伴随着阶数的增大而逐渐减小，并无截断点，这时采取移动平均过程比较经济（亦即模型当中所包含的的参数较少）。

       设若时间序列的自相关函数只是伴随着阶数的增加而逐渐衰减，并无截断点，但其偏自相关函数却有截断点，这时宜采用自回归过程。

       设若时间序列的自相关函数和偏自相关函数都只是伴随着阶数的增加而逐渐衰减，但均无截断点，则无论是采用自回归模型还是采用移动平均模型，其中所包含的的待估参数都过多。这时，宜采用自回归移动平均过程ARMA（p,q）。

       所谓的自回归移动平均模型(Autoregressive Moving Average,ARMA)，就是设法将自回归过程AR和移动平均过程MA结合起来，共同模拟产生既有时间序列样本数据的那个随机过程的模型。

       在数学上，我们总可以将一个高阶AR过程分解成某个低阶AR过程和另一个高阶AR过程之和。设若将其中所分解出来的那个高阶AR过程用一个较低阶的MA过程来替代，则那个真实的随机过程也就由低阶AR过程和高阶AR过程之和，变换成低阶AR过程与低阶MA过程之和。这就是自回归移动平均模型的基本思路。

       可见，ARMA（p,q）是一种比AR(p）和MA(q)更具普遍性的模型。而AR(p）模型和MA(q)模型可分别理解为ARMA模型的两个特例(ARMA（P,0)和ARMA(0,q))。实践中的任何时间序列都可以使用ARMA（p,q）这个模型来模拟。而且经济计量的实践经验表明，p的q的取值一般都不会超过2。

       需要指出的是，AR(p)、MA(q)和ARMA(p,q)都是平稳随机过程。但在经济计量的实践中，我们所获得的时间序列经常会呈现出系统性地上升或下降等趋势。有些时间序列还呈现出周而复始的周期性波动。这样的时间序列肯定产生于非平稳的随机过程，从而不可以直接套用诸如AR(p)、MA(q)或ARMA(p,q)之类的平稳随机过程来模拟。

       对于非平稳的时间序列，首先应将其平稳化。其中，差分变换是最常用的平稳化方法。然后再使用  AR(p)、MA(q)或ARMA(p,q)来模拟已平稳化的随机过程。这就是所谓的差分自回归移动平均模型(Autoregressive Integrated Moving Average Model），简记为ARIMA(p,d,q)。其中的d是实施差分变换的次数。

       由此可见，ARIMA（p,d,q）是一种比ARMA（p,q）更为普遍性的模型。而ARMA（p,q）可理解为ARIMA（p,d,q）的特例(ARIMA（p,0,q）)。

       对于一组给定的时间序列数据，依照上述思路寻找一个能产生这组数据的随机过程的ARIMA（p,d,q）模型方法，称为博克斯-詹金斯(Box-Jenkins)方法。它是当今主流时间序列分析理论与方法的基础。

** 不存在封闭解
   是指有解但是我们就是就是求不出来，可以利用数值方法估计一下。
** 残差
  残差在数理统计中是指实际观察值与估计值（拟合值）之间的差。“残差”蕴含了有关模型基本假设的重要信息。

  如果回归模型正确的话， 我们可以将残差看作误差的观测值。
* R代码解释
** VAR 源代码
#+BEGIN_SRC R
function (x, p = 1, output = T, include.mean = T, fixed = NULL) 
{
  if (!is.matrix(x)) 
    x = as.matrix(x)
  Tn = dim(x)[1]
  k = dim(x)[2]
  if (p < 1) 
    p = 1
  idm = k * p
  ne = Tn - p
  ist = p + 1
  y = x[ist:Tn, ]
  if (include.mean) {
    idm = idm + 1
    xmtx = cbind(rep(1, ne), x[p:(Tn - 1), ])
  }
  else {
    xmtx = x[p:(Tn - 1), ]
  }
  if (p > 1) {
    for (i in 2:p) {
      xmtx = cbind(xmtx, x[(ist - i):(Tn - i), ])
    }
  }
  ndim = ncol(xmtx)
  if (length(fixed) == 0) {
    paridx = matrix(1, ndim, k)
  }
  else {
    paridx = fixed
  }
  res = NULL
  beta = matrix(0, ndim, k)
  sdbeta = matrix(0, ndim, k)
  npar = 0
  for (i in 1:k) {
    idx = c(1:ndim)[paridx[, i] == 1]
    resi = y[, i]
    if (length(idx) > 0) {
      xm = as.matrix(xmtx[, idx])
      npar = npar + dim(xm)[2]
      xpx = t(xm) %*% xm
      xpxinv = solve(xpx)
      xpy = t(xm) %*% as.matrix(y[, i], ne, 1)
      betai = xpxinv %*% xpy
      beta[idx, i] = betai
      resi = y[, i] - xm %*% betai
      nee = dim(xm)[2]
      sse = sum(resi * resi)/(Tn - p - nee)
      dd = diag(xpxinv)
      sdbeta[idx, i] = sqrt(dd * sse)
    }
    res = cbind(res, resi)
  }
  sse = t(res) %*% res/(Tn - p)
  aic = 0
  bic = 0
  hq = 0
  Phi = NULL
  Ph0 = NULL
  jst = 0
  if (include.mean) {
    Ph0 = beta[1, ]
    se = sdbeta[1, ]
    if (output) {
      cat("Constant term:", "\n")
      cat("Estimates: ", Ph0, "\n")
      cat("Std.Error: ", se, "\n")
    }
    jst = 1
  }
  if (include.mean) {
    for (i in 1:k) {
      if (abs(Ph0[i]) > 1e-08) 
        npar = npar - 1
    }
  }
  if (output) 
    cat("AR coefficient matrix", "\n")
  for (i in 1:p) {
    phi = t(beta[(jst + 1):(jst + k), ])
    se = t(sdbeta[(jst + 1):(jst + k), ])
    if (output) {
      cat("AR(", i, ")-matrix", "\n")
      print(phi, digits = 3)
      cat("standard error", "\n")
      print(se, digits = 3)
    }
    jst = jst + k
    Phi = cbind(Phi, phi)
  }
  if (output) {
    cat(" ", "\n")
    cat("Residuals cov-mtx:", "\n")
    print(sse)
    cat(" ", "\n")
  }
  dd = det(sse)
  d1 = log(dd)
  aic = d1 + (2 * npar)/Tn
  bic = d1 + log(Tn) * npar/Tn
  hq = d1 + 2 * log(log(Tn)) * npar/Tn
  if (output) {
    cat("det(SSE) = ", dd, "\n")
    cat("AIC = ", aic, "\n")
    cat("BIC = ", bic, "\n")
    cat("HQ  = ", hq, "\n")
  }
  VAR <- list(data = x, cnst = include.mean, order = p, coef = beta, 
    aic = aic, bic = bic, hq = hq, residuals = res, secoef = sdbeta, 
    Sigma = sse, Phi = Phi, Ph0 = Ph0)
}
#+END_SRC


#+END_SRC
** VMA函数
VMA模型主要用到了书上的P85页 3.7 下面的函数。也用到了3.7上面的一列，我们要估计的是θ （维度是1*k）。

要最小化的最大似然函数和nlminb函数定义是这样的：

LLKvma <- function(par, zt = zt, q = q, fixed = fix1, include.mean = include.mean) 

fit = nlminb(start = ParMA, objective = LLKvma, zt = da, 
                 fixed = fixed, include.mean = include.mean, q = q, 
                 lower = lowerBounds, upper = upperBounds, control = list(trace = 3))

*参数* ：start是我们给定的估计参数的初始值，objective是最大使然函数里的那个我们要最小化他的返回值的那个函数，zt是实际数据da，q是VMA(q)中的那个q。

其中，par是我们要估计的参数，即μ和θ_i,一共是(kq+1)*k个变量（μ是1*k，θ_i是1*k,一共q个θ）。
-sum(log(dmvonorm(at,rep(0,k),sig)) == 书中的Σlog(P(a_t|θ1，Σa)) 

* R语言函数的一些注释
** diff(x,lag,differences)
diff是返回滞后的迭代差异。

意思就是dif(1:10,2)的话就是所有数减去他的前2个数的值，所以是（2,2,2,2,2,2,2,2）一共8个数，因为1和2没有滞后2个的数
同理diff(1:10,6) = (6,6,6,6)

参数：
  + x： 数据
  + lag：滞后的步数
  + differences：没用到所以暂时不研究

** rmvnorm
   rmvnorm函数生成一个正态分布的数据，其中300是向量矩阵，rep(0.2)=(0,0),表示两列向量的均值都是0，di
** Mod(V)  
复数的函数，如果V1 = x + yi ，那么Mod(V1) = sqrt(x^2 + y^2) .即求负数V1的模
** solve(A,B) 
这个函数是求解 Ax=B的x，即 x = B%*%A^-1。

如果只是solve(A)的话，那么就是求A矩阵的逆
** nlminb 函数   
可以用来计算极大似然函数
[[https://cosx.org/2009/07/maximum-likelihood-estimation-in-r/][参考网址]]  上是使用实例讲的很清楚
** dnorm(x,mean,sd)
生成的是在N(mean,sd)的正态分布中取x的概率，如果x是个向量的话那么就是每个数的概率，

反正length(x) = length(dnorm(x,mean,sd))

_______________________________________________________________________________________
* QUESTIONS
1. 方程的phi是怎么确定的？？在例子程序中，都是直接给出来的。那么在实际中呢？？？
   解：是估计出来的，在模型估计中有公式
2. VAR模型中的Sigmaa是什么用途的？？
   解：Sigma是残差协方差矩阵，是用来进行模型估计的。在VAR(p)模型的估计过程，主要估计的就是Phi和Sigma。
3. 还不知道怎么怎么评价VAR模型？是通过什么指标来评测怎么样算好这么样算不好？？
4. sigma（协方差矩阵）的意义是什么
5. include.mean 的意义是什么？？
   
* 改成C语言的可能障碍
** eigen函数 是矩阵的谱分解函数，不知道C语言里面有没有相应的函数来解决矩阵的谱分解
** solve函数来求矩阵的逆
** 还有一个nlminb函数是一个优化函数，不知道具体是怎么实现的。可能还需要在深入看这个函数的源代码
nlminb(start, objective, gradient = NULL, hessian = NULL, ...,
       scale = 1, control = list(), lower = -Inf, upper = Inf)

一些参数：
+ objective                   <-看这个参数的解释是这个方法是要最小化一个方法？？	
 Function to be minimized（要最小化的方法）. Must return a scalar value. The first argument to objective 
 is the vector of parameters to be optimized, whose initial values are supplied through start.
 Further arguments (fixed during the course of the optimization) to objective may be specified as well
 (see ...).
+ start	
numeric vector, initial values for the parameters to be optimized.



* 一些函数的c语言版本：
** eigen函数
#+BEGIN_SRC c -
  //------------------------------------头文件---------------------------------  
  #include <stdio.h>
  #include <stdlib.h>
  #include <math.h>
  #include <time.h>
  //--------------------------这里是一些定义的结构体和数据类型---------  
  //纯C里面定义的布尔类型  
  typedef enum{False = 0,True = 1}Bool;  
  //定义矩阵元素的类型为matrixType  
  typedef double matrixType;  
   
  //此结构体用来表示矩阵，其中row为行，column为列，height为高，array用来存放矩阵元素(用一维来模拟二维/三维)  
  typedef struct  
  {  
    unsigned  row,column,height;  
    matrixType *array; //使用时，必须对*array进行初始化  
  }Matrix;  
   
  //---------下面是QR分解，求解线性方程所用到的一些函数-----------  
  /* 
     matrix为要设置大小并分配内存的矩阵，row、column、height分别为行，列，高。 
     函数调用成功则则返回true,否则返回false 
  ,*/  
  Bool SetMatrixSize(Matrix *matrix ,const unsigned row,const unsigned column,const unsigned height)  
  {  
    unsigned size = row  * column * height * sizeof(matrixType);  
    if(size <= 0 )  
      {  
        return False;  
      }  
     
    matrix->array = (matrixType*)malloc(size);  
   
    //如果分配内存成功  
    if(matrix->array)  
      {  
        matrix->row = row;  
        matrix->column = column;  
        matrix->height = height;  
        return True;  
      }  
    else  
      {  
        matrix->row = matrix->column = matrix->height = 0;  
        return False;  
      }  
  }  
   
  //设置Matrix矩阵中的所有元素大小为ele  
  void SetMatrixEle(Matrix *matrix,matrixType ele)  
  {  
    unsigned size = matrix->row * matrix->column * matrix->height;  
    unsigned i;  
   
    for(i = 0;i < size;++i)  
      {  
        matrix->array[i] = ele;  
      }  
  }  
   
  //设置Matrix矩阵中的所有元素大小为0  
  void SetMatrixZero(Matrix*matrix)  
  {  
    SetMatrixEle(matrix,0);  
  }  
   
  //判断矩阵是否为空，若为空则返回1，否则返回0  
  Bool IsNullMatrix(const Matrix* matrix)  
  {  
    unsigned size = matrix->row * matrix->column * matrix->column;  
   
    if(size <= 0 || matrix->array == NULL)  
      {  
        return True;  
      }  
    return False;  
  }  
   
  //销毁矩阵，即释放为矩阵动态分配的内存,并将矩阵的长宽高置0  
  void DestroyMatrix(Matrix *matrix)  
  {  
    if(!IsNullMatrix(matrix))  
      {  
        free(matrix->array);  
        matrix->array = NULL;  
      }  
   
    matrix->row = matrix->column = matrix->height = 0;  
  }  
   
  //计算矩阵可容纳元素个数，即return row*column*height  
  unsigned MatrixCapacity(const Matrix*matrix)  
  {  
    return matrix->row * matrix->column * matrix->height;  
  }  
   
   
  //||matrix||_2  求A矩阵的2范数  
  matrixType MatrixNorm2(const Matrix *matrix)  
  {  
    unsigned size = matrix->row * matrix->column *matrix->height;  
    unsigned i;  
    matrixType norm = 0;  
   
    for(i = 0;i < size;++i)  
      {  
        norm +=  (matrix->array[i]) *(matrix->array[i]);  
      }  
   
    return (matrixType)sqrt(norm);  
  }  
   
  //matrixB = matrix(:,:,height)即拷贝三维矩阵的某层，若matrix为二维矩阵，需将height设置为0  
  Bool CopyMatrix(Matrix* matrixB,Matrix *matrix,unsigned height)  
  {  
    unsigned size,i;  
    Matrix matrixA;  
   
    //判断height值是否正确  
    if(height < 0 || height >= matrix->height)  
      {  
        printf("ERROR: CopyMatrix() parameter error！\n");  
        return False;  
      }  
   
    //将matrix(:,:,height) 转换为二维矩阵matrixA  
    matrixA.row = matrix->row;  
    matrixA.column = matrix->column;  
    matrixA.height = 1;  
    matrixA.array = matrix->array + height * matrix->row * matrix->column;  
   
    //判断两矩阵指向的内存是否相等  
    if(matrixA.array == matrixB->array)  
      {  
        return True;  
      }  
   
    //计算matrixA的容量  
    size = MatrixCapacity(&matrixA);  
    //判断matrixB的容量与matrixA的容量是否相等  
    if( MatrixCapacity(matrixB)!= size)  
      {  
        DestroyMatrix(matrixB);  
        SetMatrixSize(matrixB,matrixA.row,matrixA.column,matrixA.height);  
      }  
    else  
      {  
        matrixB->row = matrixA.row;  
        matrixB->column = matrixA.column;  
        matrixB->height = matrixA.height;  
      }  
   
    for(i = 0;i < size;++i)  
      {  
        matrixB->array[i] = matrixA.array[i];  
      }  
   
    return True;  
  }  
   
  //matrixC = matrixA * matrixB  
  Bool MatrixMulMatrix(Matrix *matrixC,const Matrix* matrixA,const Matrix* matrixB)  
  {  
    size_t row_i,column_i,i;  
    size_t indexA,indexB,indexC;  
    matrixType temp;  
    Matrix tempC;  
   
    if(IsNullMatrix(matrixA) || IsNullMatrix(matrixB))  
      {  
        return False;  
      }  
   
    if(matrixA->column != matrixB->row  )  
      {  
        return False;  
      }  
   
    if(MatrixCapacity(matrixC) != matrixA->row * matrixB->column)  
      {  
        SetMatrixSize(&tempC,matrixA->row,matrixB->column,1);  
      }  
    else  
      {  
        tempC.array = matrixC->array;  
        tempC.row = matrixA->row;  
        tempC.column = matrixB->column;  
        tempC.height = 1;  
      }  
   
    for(row_i = 0;row_i < tempC.row;++row_i)  
      {  
        for(column_i = 0;column_i < tempC.column;++column_i)  
          {  
            temp = 0;  
            for(i = 0;i < matrixA->column;++i)  
              {  
                indexA =  row_i * matrixA->column + i;  
                indexB =  i * matrixB->column + column_i;  
   
                temp += matrixA->array[indexA] * matrixB->array[indexB];  
              }  
            indexC = row_i * tempC.column + column_i;  
   
            tempC.array[indexC] = temp;  
          }  
      }  
   
   
    if(tempC.array != matrixC->array)  
      {  
        DestroyMatrix(matrixC);  
   
        matrixC->array = tempC.array;  
      }  
   
    matrixC->row = tempC.row;  
    matrixC->column = tempC.column;  
    matrixC->height = tempC.height;  
   
   
   
    return True;  
  }  
   
  //对vector中所有元素排序，sign= 0 时为升序，其余为降序  
  void SortVector(Matrix *vector,int sign)  
  {  
    matrixType mid;  
    int midIndex;  
    int size = MatrixCapacity(vector);  
    int i,j;  
   
    if(0 == sign)  
      {  
        for(i = 0;i < size;++i)  
          {  
            mid = vector->array[i];  
            midIndex = i;  
            for( j = i + 1; j < size ; ++j)  
              {  
                if(mid > vector->array[j])  
                  {  
                    mid = vector->array[j];  
                    midIndex = j;  
                  }  
              }  
   
            vector->array[midIndex] = vector->array[i];  
            vector->array[i] = mid;  
          }  
      }  
    else  
      {  
        for(i = 0;i < size;++i)  
          {  
            mid = vector->array[i];  
            midIndex = i;  
            for( j = i + 1; j < size ; ++j)  
              {  
                if(mid < vector->array[j])  
                  {  
                    mid = vector->array[j];  
                    midIndex = j;  
                  }  
              }  
   
            vector->array[midIndex] = vector->array[i];  
            vector->array[i] = mid;  
          }  
      }  
  }  
   
  //打印矩阵  
  void PrintMatrix(const Matrix *matrix)  
  {  
    size_t row_i,column_i,height_i,index;  
   
    for(height_i = 0;height_i < matrix->height;++height_i)  
      {  
        (matrix->height == 1) ? printf("[:,:] = \n"):printf("[%d,:,:] = \n",height_i);  
   
        for(row_i = 0;row_i < matrix->row;++row_i)  
          {  
            for(column_i = 0;column_i < matrix->column;++column_i)  
              {  
                index = height_i * matrix->row * matrix->column + row_i * matrix->column + column_i;  
                printf("%12.4g",matrix->array[index]);  
              }  
            printf("\n");  
          }  
      }  
  }  
   
  //----------------------QR分解-------------------------------------------  
   
  //将A分解为Q和R  
  void QR(Matrix *A,Matrix *Q,Matrix *R)  
  {  
    unsigned  i,j,k,m;  
    unsigned size;  
    const unsigned N = A->row;  
    matrixType temp;  
   
    Matrix a,b;  
   
    //如果A不是一个二维方阵，则提示错误，函数计算结束  
    if(A->row != A->column || 1 != A->height)  
      {  
        printf("ERROE: QR() parameter A is not a square matrix!\n");  
        return;  
      }  
   
    size = MatrixCapacity(A);  
    if(MatrixCapacity(Q) != size)  
      {  
        DestroyMatrix(Q);  
        SetMatrixSize(Q,A->row,A->column,A->height);  
        SetMatrixZero(Q);  
      }  
    else  
      {  
        Q->row = A->row;  
        Q->column = A->column;  
        Q->height = A->height;  
      }  
   
    if(MatrixCapacity(R)  != size)  
      {  
        DestroyMatrix(R);  
        SetMatrixSize(R,A->row,A->column,A->height);  
        SetMatrixZero(R);  
      }  
    else  
      {  
        R->row = A->row;  
        R->column = A->column;  
        R->height = A->height;  
      }  
   
    SetMatrixSize(&a,N,1,1);  
    SetMatrixSize(&b,N,1,1);  
   
    for(j = 0 ; j < N;++j)  
      {  
        for(i = 0;i < N; ++i)  
          {  
            a.array[i] = b.array[i] = A->array[i * A->column + j];  
          }  
   
        for(k  = 0; k  < j; ++k)  
          {  
            R->array[k * R->column + j] = 0;  
   
            for(m = 0;m < N; ++m)  
              {  
                R->array[k * R->column + j] += a.array[m] * Q->array[m * Q->column + k];  
              }  
   
            for(m = 0;m < N; ++m)  
              {  
                b.array[m] -= R->array[k * R->column + j] * Q->array[m * Q->column + k];  
              }  
          }  
   
        temp = MatrixNorm2(&b);  
        R->array[j * R->column + j] = temp;  
   
        for(i = 0; i < N; ++i)  
          {  
            Q->array[i * Q->column + j] = b.array[i] / temp;  
          }  
      }  
   
    DestroyMatrix(&a);  
    DestroyMatrix(&b);  
  }  
   
  //----------------------使用特征值计算矩阵特征向量-----------------  
  //eigenVector为计算结果即矩阵A的特征向量  
  //eigenValue为矩阵A的所有特征值，  
  //A为要计算特征向量的矩阵  
  void Eigenvectors(Matrix *eigenVector, Matrix *A,Matrix *eigenValue)  
  {  
    unsigned i,j,q;  
    unsigned count;  
    int m;  
    const unsigned NUM = A->column;  
    matrixType eValue;  
    matrixType sum,midSum,mid;  
    Matrix temp;  
   
    SetMatrixSize(&temp,A->row,A->column,A->height);  
   
    for(count = 0; count < NUM;++count)  
      {  
        //计算特征值为eValue，求解特征向量时的系数矩阵  
        eValue = eigenValue->array[count] ;  
        CopyMatrix(&temp,A,0);  
        for(i = 0 ; i < temp.column ; ++i)  
          {  
            temp.array[i * temp.column + i] -= eValue;  
          }  
   
        //将temp化为阶梯型矩阵  
        for(i = 0 ; i < temp.row - 1 ; ++i)  
          {  
            mid = temp.array[i * temp.column + i];  
            for(j = i; j < temp.column; ++j)  
              {  
                temp.array[i * temp.column + j] /= mid;  
              }  
   
            for(j = i + 1;j < temp.row;++j)  
              {  
                mid = temp.array[j * temp.column + i];  
                for(q = i ; q < temp.column; ++q)  
                  {  
                    temp.array[j * temp.column + q] -= mid * temp.array[i * temp.column + q];  
                  }  
              }  
          }  
        midSum = eigenVector->array[(eigenVector->row - 1) * eigenVector->column + count] = 1;  
        for(m = temp.row - 2; m >= 0; --m)  
          {  
            sum = 0;  
            for(j = m + 1;j < temp.column; ++j)  
              {  
                sum += temp.array[m * temp.column + j] * eigenVector->array[j * eigenVector->column + count];  
              }  
            sum= -sum / temp.array[m * temp.column + m];  
            midSum +=  sum * sum;  
            eigenVector->array[m * eigenVector->column + count] = sum;  
          }  
   
        midSum = sqrt(midSum);  
        for(i = 0; i < eigenVector->row ; ++i)  
          {  
            eigenVector->array[i * eigenVector->column + count] /= midSum;  
          }  
      }  
    DestroyMatrix(&temp);  
  }  
  int main()  
  {  
    const unsigned NUM = 50; //最大迭代次数  
   
    unsigned N = 3;  
    unsigned k;  
   
    Matrix A,Q,R,temp;  
    Matrix eValue;  
   
   
    //分配内存  
    SetMatrixSize(&A,N,N,1);  
    SetMatrixSize(&Q,A.row,A.column,A.height);  
    SetMatrixSize(&R,A.row,A.column,A.height);  
    SetMatrixSize(&temp,A.row,A.column,A.height);  
    SetMatrixSize(&eValue,A.row,1,1);  
   
    //A设置为一个简单矩阵  
    A.array[0] = -1;  
    A.array[1] = 2;  
    A.array[2] = 1;  
    A.array[3] = 2;  
    A.array[4] = 4;  
    A.array[5] = -1;  
    A.array[6] = 1;  
    A.array[7] = 1;  
    A.array[8] = -6;  
   
   
    //拷贝A矩阵元素至temp  
    CopyMatrix(&temp,&A,0);  
   
    //初始化Q、R所有元素为0  
    SetMatrixZero(&Q);  
    SetMatrixZero(&R);  
    //使用QR分解求矩阵特征值  
    for(k = 0;k < NUM; ++k)  
      {  
        QR(&temp,&Q,&R);  
        MatrixMulMatrix(&temp,&R,&Q);  
      }  
    //获取特征值，将之存储于eValue  
    for(k = 0;k < temp.column;++k)  
      {  
        eValue.array[k] = temp.array[k * temp.column + k];  
      }  
   
    //对特征值按照降序排序  
    SortVector(&eValue,1);  
   
    //根据特征值eValue，原始矩阵求解矩阵特征向量Q  
    Eigenvectors(&Q,&A,&eValue);  
   
    //打印特征值  
    printf("特征值：");  
    PrintMatrix(&eValue);  
   
    //打印特征向量  
    printf("特征向量");  
    PrintMatrix(&Q);  
    DestroyMatrix(&A);  
    DestroyMatrix(&R);  
    DestroyMatrix(&Q);  
    DestroyMatrix(&eValue);  
    DestroyMatrix(&temp);  
   
    return 0;  
  }  

#+END_SRC
** 矩阵求逆
#+BEGIN_SRC c -n
#include<stdio.h>  
#define N 10  
int getA(int arcs[N][N],int n)//按第一行展开计算|A|  
{  
    if(n==1)  
    {  
        return arcs[0][0];  
    }  
    int ans = 0;  
    int temp[N][N];  
    int i,j,k;  
    for(i=0;i<n;i++)  
    {  
        for(j=0;j<n-1;j++)  
        {  
            for(k=0;k<n-1;k++)  
            {  
                temp[j][k] = arcs[j+1][(k>=i)?k+1:k];  
                
            }  
        }  
        int t = getA(temp,n-1);  
        if(i%2==0)  
        {  
            ans += arcs[0][i]*t;  
        }  
        else  
        {  
            ans -=  arcs[0][i]*t;  
        }  
    }  
    return ans;  
}  
void getAStart(int arcs[N][N],int n,int ans[N][N])//计算每一行每一列的每个元素所对应的余子式，组成A*  
{  
    if(n==1)  
    {  
        ans[0][0] = 1;  
        return;  
    }  
    int i,j,k,t;  
    int temp[N][N];  
    for(i=0;i<n;i++)  
    {  
        for(j=0;j<n;j++)  
        {  
            for(k=0;k<n-1;k++)  
            {  
                for(t=0;t<n-1;t++)  
                {  
                    temp[k][t] = arcs[k>=i?k+1:k][t>=j?t+1:t];  
                }  
            }  

        
            ans[j][i]  =  getA(temp,n-1);  
            if((i+j)%2 == 1)  
            {  
                ans[j][i] = - ans[j][i];  
            }  
        }  
    }  
}  

int main()  
{  
    int arcs[N][N];  
    int astar[N][N];  
    int i,j;  
    int n;  
    while(scanf("%d",&n)!=EOF && n)  
    {  
        for(i=0;i<n;i++)  
        {  
            for(j=0;j<n;j++)  
            {  
                scanf("%d",&arcs[i][j]);  
            }  
        }  
    
        int a = getA(arcs,n);  
        if(a==0)  
        {  
            printf("can not transform!\n");  
        }  
        else  
        {  
            getAStart(arcs,n,astar);  
            for(i=0;i<n;i++)  
            {  
                for(j=0;j<n;j++)  
                {  
                    printf("%.3lf ",(double)astar[i][j]/a);  
                }  
                printf("\n");  
            }  
        }  
        printf("\n");  

    }  
    

    return 0;  
}  

#+END_SRC




* 随想
多元时间序列有多个时间序列，之所以要使用多元原因是因为可能两只股票之间存在一定的联系，最简单的我们可以想到的是z_1t受z_2(t-1) 和z_1(t-1),也就是z1和z2前面数值的影响，受其影响的大小体现在参数φ里面，在估计过程中
我们就能将相关性大的参数估计的数大而相关性小的估计的参数小。像P21页解释的那样，要是φ1,21 ！= 0 的话说明z_2t 依赖于z_1t的过去值。这样多元时间序列的关系就体现出来了。

另外一个比较简单的模型是VMA模型。就想P79页说的那样，可以列出z_1 和 z_2t 的VMA表达式。这里面的参数是θ和∑_a 。使用的方法是极大似然算法。
在R代码里，有现成的函数nlminb来做这个极大似然函数的优化参数使这函数的object函数返回的值最小。

eVMA相比较于VMA来说假设不一样，VMA假设的是a_0 = 0 ，而eVMA假设的是a_0是一个随机变量。所以做最大似然估计的时候需要做的工作要多一些。

用什么来决定用VMA还是eVMA呢？-一般来说当样本数比较大尤其是VMA(q)可逆的时候，这两个似然估计的函数相似。如果不可逆的话选用eVMA比较合适。
模型可逆的条件在每节都有讨论。


** 一些东西短时间内看不明白，不要放弃，坚持每天看的话真的是每天都有顿悟的时刻的。



